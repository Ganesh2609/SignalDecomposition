{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fftpack import fft, ifft, fftfreq\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import vmdpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = r\"./neurovoz_v3/data/audio_features/audio_features.csv\"\n",
    "audio_directory = r\"./neurovoz_v3/data/audios\"\n",
    "imf_directory = r\"./Outputs/VMD/IMFs\"\n",
    "residual_directory = r\"./Outputs/VMD/Residual\"\n",
    "reconstructed_directory = r\"./Outputs/VMD/Reconstructed_Signal\"\n",
    "plot_directory = r\"./Outputs/VMD/Plots\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmd(signal, alpha=120, tau=0, K=5, DC=0, init=1, tol=1e-7):\n",
    "    print(\"VMD started\")\n",
    "    # Ensure signal is a numpy array\n",
    "    signal = np.array(signal, dtype=np.float64)\n",
    "    \n",
    "    # Normalize the signal (optional)\n",
    "    signal = signal / np.max(np.abs(signal))\n",
    "\n",
    "    # Perform VMD\n",
    "    modes, _, _ = vmdpy.VMD(signal, alpha, tau, K, DC, init, tol)\n",
    "    print(modes.shape)\n",
    "    # Reconstruct the signal from the modes\n",
    "    reconstructed_signal = np.sum(modes, axis=0, dtype=np.float64)\n",
    "    print(reconstructed_signal.shape)\n",
    "    # Calculate residual (signal minus reconstructed signal)\n",
    "    residual = signal - reconstructed_signal\n",
    "    print(\"VMD completed\")\n",
    "    return modes, residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def VMD_torch(f, alpha, tau, K, DC, init, tol, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Variational Mode Decomposition (VMD) implemented in PyTorch with device-agnostic initialization\n",
    "    and optimized FFT operations.\n",
    "\n",
    "    Parameters:\n",
    "    ---------\n",
    "    f : numpy.ndarray\n",
    "        Input signal (1D array).\n",
    "    alpha : float\n",
    "        Bandwidth constraint parameter.\n",
    "    tau : float\n",
    "        Lagrange multiplier for enforcing signal reconstruction fidelity.\n",
    "    K : int\n",
    "        Number of modes to decompose the signal into.\n",
    "    DC : bool\n",
    "        If True, constrain the first mode to have zero mean (DC component).\n",
    "    init : int\n",
    "        Initialization mode for center frequencies:\n",
    "        - 1: Linear initialization.\n",
    "        - 2: Random logarithmic initialization.\n",
    "        - 0: All frequencies start at zero.\n",
    "    tol : float\n",
    "        Convergence tolerance.\n",
    "    device : str\n",
    "        Target device for computation ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    u : numpy.ndarray\n",
    "        Decomposed modes in the time domain.\n",
    "    u_hat_final : numpy.ndarray\n",
    "        Fourier-domain representation of decomposed modes.\n",
    "    omega : numpy.ndarray\n",
    "        Center frequencies of the modes.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if device == \"cuda\" and torch.cuda.is_available() else \"cpu\")\n",
    "    f = torch.tensor(f, device=device, dtype=torch.float32).contiguous()\n",
    "    \n",
    "    # Ensure even length for the input signal\n",
    "    if f.numel() % 2 != 0:\n",
    "        print(\"Input signal must have an even length.\")\n",
    "        f = f[:-1]\n",
    "\n",
    "    # Period and sampling frequency\n",
    "    fs = 1.0 / len(f)\n",
    "    ltemp = len(f) // 2\n",
    "\n",
    "    # Mirrored signal\n",
    "    fMirr = torch.cat([f[:ltemp].flip(0), f, f[-ltemp:].flip(0)], dim=0)\n",
    "\n",
    "    # Time and spectral domain discretization\n",
    "    T = len(fMirr)\n",
    "    freqs = torch.arange(1, T + 1, device=device) / T - 0.5 - (1 / T)\n",
    "\n",
    "    # FFT of the mirrored signal\n",
    "    f_hat = torch.fft.fftshift(torch.fft.fft(fMirr))\n",
    "    f_hat_plus = f_hat.clone()\n",
    "    f_hat_plus[:T // 2] = 0\n",
    "\n",
    "    # Initialize omega\n",
    "    if init == 1:\n",
    "        omega_curr = torch.linspace(0, 0.5, K, device=device)\n",
    "    elif init == 2:\n",
    "        omega_curr = torch.sort(\n",
    "            torch.exp(torch.log(fs) + (torch.log(0.5) - torch.log(fs)) * torch.rand(K, device=device))\n",
    "        )[0]\n",
    "    else:\n",
    "        omega_curr = torch.zeros(K, device=device)\n",
    "    if DC:\n",
    "        omega_curr[0] = 0\n",
    "\n",
    "    # Initialize variables\n",
    "    lambda_curr = torch.zeros(T, dtype=torch.cfloat, device=device)\n",
    "    u_curr = torch.zeros((T, K), dtype=torch.cfloat, device=device)\n",
    "    u_prev = torch.zeros((T, K), dtype=torch.cfloat, device=device)\n",
    "    omega_history = torch.zeros((500, K), device=device)\n",
    "\n",
    "    # Convergence parameters\n",
    "    uDiff = tol + torch.finfo(torch.float32).eps\n",
    "    n = 0\n",
    "    Niter = 500\n",
    "\n",
    "    while uDiff > tol and n < Niter - 1:\n",
    "        u_prev.copy_(u_curr)\n",
    "        sum_uk = torch.sum(u_prev, dim=1, keepdim=True) - u_prev[:, 0:1]\n",
    "\n",
    "        # Update first mode\n",
    "        u_curr[:, 0] = (f_hat_plus - sum_uk.squeeze() - lambda_curr / 2) / (1 + alpha * (freqs - omega_curr[0]) ** 2)\n",
    "        if not DC:\n",
    "            omega_curr[0] = torch.sum(\n",
    "                freqs[T // 2:] * torch.abs(u_curr[T // 2:, 0]) ** 2\n",
    "            ) / torch.sum(torch.abs(u_curr[T // 2:, 0]) ** 2)\n",
    "\n",
    "        # Update remaining modes\n",
    "        for k in range(1, K):\n",
    "            sum_uk += u_curr[:, k - 1:k] - u_prev[:, k:k + 1]\n",
    "            u_curr[:, k] = (f_hat_plus - sum_uk.squeeze() - lambda_curr / 2) / (\n",
    "                1 + alpha * (freqs - omega_curr[k]) ** 2\n",
    "            )\n",
    "            omega_curr[k] = torch.sum(\n",
    "                freqs[T // 2:] * torch.abs(u_curr[T // 2:, k]) ** 2\n",
    "            ) / torch.sum(torch.abs(u_curr[T // 2:, k]) ** 2)\n",
    "\n",
    "        # Update Lagrange multiplier\n",
    "        lambda_curr += tau * (torch.sum(u_curr, dim=1) - f_hat_plus)\n",
    "\n",
    "        # Check convergence\n",
    "        omega_history[n + 1] = omega_curr\n",
    "        n += 1\n",
    "        uDiff = torch.sqrt(torch.sum(torch.abs(u_curr - u_prev) ** 2) / u_curr.numel())\n",
    "\n",
    "    # Truncate omega history\n",
    "    omega = omega_history[:n]\n",
    "\n",
    "    # Reconstruct signal modes in the time domain\n",
    "    u_hat = torch.zeros((T, K), dtype=torch.cfloat, device=device)\n",
    "    u_hat[T // 2:, :] = u_curr[T // 2:, :]\n",
    "    u_hat[:T // 2, :] = torch.conj(u_curr[T // 2:T, :].flip(0))  # Fix slicing range\n",
    "    u = torch.real(torch.fft.ifft(torch.fft.ifftshift(u_hat, dim=0), dim=0))\n",
    "\n",
    "        # Extract the relevant part of the signal with robust slicing\n",
    "    start = max(0, T // 4)\n",
    "    end = min(u.shape[1], 3 * T // 4)\n",
    "    if start >= end:\n",
    "        raise ValueError(f\"Invalid slicing range: start={start}, end={end}, T={T}\")\n",
    "    u = u[:, start:end]\n",
    "\n",
    "    # Assert non-empty result\n",
    "    assert u.numel() > 0, \"u tensor is empty after slicing! Check input signal and slicing range.\"\n",
    "\n",
    "\n",
    "    # Fourier-domain representation of the final modes\n",
    "    u_hat_final = torch.fft.fftshift(torch.fft.fft(u, dim=0), dim=0)\n",
    "\n",
    "\n",
    "    return u.cpu().numpy(), u_hat_final.cpu().numpy(), omega.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to check GPU memory\n",
    "def check_gpu_memory():\n",
    "    \"\"\"\n",
    "    Print current GPU memory usage\n",
    "    \"\"\"\n",
    "    mem_info = cp.cuda.runtime.memGetInfo()\n",
    "    free_mem = mem_info[0] / 1024**2  # Convert to MB\n",
    "    total_mem = mem_info[1] / 1024**2\n",
    "    used_mem = total_mem - free_mem\n",
    "    print(f\"GPU Memory Usage:\")\n",
    "    print(f\"Total: {total_mem:.2f} MB\")\n",
    "    print(f\"Used:  {used_mem:.2f} MB\")\n",
    "    print(f\"Free:  {free_mem:.2f} MB\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample signal\n",
    "    t = np.linspace(0, 1, 1000)\n",
    "    f1, f2 = 2, 10\n",
    "    signal = np.sin(2*np.pi*f1*t) + np.sin(2*np.pi*f2*t)\n",
    "    \n",
    "    # VMD parameters\n",
    "    alpha = 2000\n",
    "    tau = 0\n",
    "    K = 2\n",
    "    DC = False\n",
    "    init = 1\n",
    "    \n",
    "    # Decompose signal\n",
    "    modes, spectra, frequencies = VMD_torch(signal, alpha, tau, K, DC, init, 1e-6)\n",
    "    \n",
    "    print(f\"Number of modes extracted: {modes.shape[0]}\")\n",
    "    print(f\"Length of each mode: {modes.shape[1]}\")\n",
    "    print(f\"Final center frequencies: {frequencies[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_modes_and_reconstruct(modes, residual, sample_rate, original_signal, base_filename):\n",
    "    \"\"\"Save modes, residual, and reconstructed signal with length adjustment.\"\"\"\n",
    "    \n",
    "    reconstructed_signal = np.zeros_like(original_signal, dtype=np.float64)\n",
    "    \n",
    "    for i, mode in enumerate(modes[:5]):  \n",
    "    \n",
    "        mode = np.pad(mode, (0, len(original_signal) - len(mode)), 'constant')[:len(original_signal)]\n",
    "        mode_path = os.path.join(imf_directory, f\"{base_filename}_mode_{i+1}.wav\")\n",
    "        mode = (mode / np.max(np.abs(mode))) * 32767 if np.max(np.abs(mode)) > 0 else mode  # Normalize mode\n",
    "        mode = mode.astype(np.int16)\n",
    "        wavfile.write(mode_path, sample_rate, mode)\n",
    "        reconstructed_signal += mode\n",
    "\n",
    "    residual = np.pad(residual, (0, len(original_signal) - len(residual)), 'constant')[:len(original_signal)]\n",
    "    residual_path = os.path.join(residual_directory, f\"{base_filename}_residual.wav\")\n",
    "    wavfile.write(residual_path, sample_rate, residual.astype(np.int16))\n",
    "\n",
    "    reconstructed_signal += residual\n",
    "    if np.max(np.abs(reconstructed_signal)) > 0:\n",
    "        reconstructed_signal /= np.max(np.abs(reconstructed_signal)) \n",
    "\n",
    "    reconstructed_path = os.path.join(reconstructed_directory, f\"{base_filename}_reconstructed.wav\")\n",
    "    wavfile.write(reconstructed_path, sample_rate, (reconstructed_signal * 32767).astype(np.int16))\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, mode in enumerate(modes[:5]):\n",
    "        plt.subplot(6, 1, i+1)\n",
    "        plt.plot(mode)\n",
    "        plt.title(f\"Mode {i+1}\")\n",
    "    plt.subplot(6, 1, 6)\n",
    "    plt.plot(residual)\n",
    "    plt.title(\"Residual\")\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(plot_directory, f\"{base_filename}_modes_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_modes_and_reconstruct_vmd(modes, sample_rate, original_signal, base_filename):\n",
    "\n",
    "    # Initialize reconstructed signal\n",
    "    reconstructed_signal = np.zeros_like(original_signal, dtype=np.float64)\n",
    "\n",
    "    # Save each mode\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Adjust mode length to match original signal\n",
    "        mode = np.pad(mode, (0, len(original_signal) - len(mode)), 'constant')[:len(original_signal)]\n",
    "\n",
    "        # Save mode as WAV\n",
    "        mode_path = os.path.join(imf_directory, f\"{base_filename}_mode_{i+1}.wav\")\n",
    "        if np.max(np.abs(mode)) > 0:\n",
    "            mode = (mode / np.max(np.abs(mode))) * 32767  # Normalize mode\n",
    "        mode = mode.astype(np.int16)\n",
    "        wavfile.write(mode_path, sample_rate, mode)\n",
    "\n",
    "        # Add to reconstructed signal\n",
    "        reconstructed_signal += mode\n",
    "\n",
    "    # # Save residual\n",
    "    # residual = np.pad(residual, (0, len(original_signal) - len(residual)), 'constant')[:len(original_signal)]\n",
    "    # residual_path = os.path.join(residual_directory, f\"{base_filename}_residual.wav\")\n",
    "    # residual = (residual / np.max(np.abs(residual))) * 32767 if np.max(np.abs(residual)) > 0 else residual\n",
    "    # wavfile.write(residual_path, sample_rate, residual.astype(np.int16))\n",
    "\n",
    "    # Add residual to reconstructed signal\n",
    "    reconstructed_signal += residual\n",
    "    if np.max(np.abs(reconstructed_signal)) > 0:\n",
    "        reconstructed_signal /= np.max(np.abs(reconstructed_signal))\n",
    "\n",
    "    # Save reconstructed signal\n",
    "    reconstructed_path = os.path.join(reconstructed_directory, f\"{base_filename}_reconstructed.wav\")\n",
    "    wavfile.write(reconstructed_path, sample_rate, (reconstructed_signal * 32767).astype(np.int16))\n",
    "\n",
    "    # Plot modes and residual\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, mode in enumerate(modes[:5]):  # Limit to the first 5 modes for plotting\n",
    "        plt.subplot(6, 1, i+1)\n",
    "        plt.plot(mode, label=f\"Mode {i+1}\")\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.subplot(6, 1, 6)\n",
    "    plt.plot(residual, label=\"Residual\", color='red')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot\n",
    "    plot_path = os.path.join(plot_directory, f\"{base_filename}_modes_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_file(row):\n",
    "    \"\"\"\n",
    "    Process each audio file for VMD (Variational Mode Decomposition).\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): A dictionary containing audio file metadata (e.g., path).\n",
    "    \"\"\"\n",
    "    # Extract and clean the relative path\n",
    "    relative_path = row['AudioPath'].strip()\n",
    "    \n",
    "    if relative_path.startswith('../data/audios/'):\n",
    "        relative_path = relative_path.replace('../data/audios/', '')\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(audio_directory, relative_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Read the audio file\n",
    "        sample_rate, data = wavfile.read(file_path)\n",
    "\n",
    "        # Convert stereo to mono if needed\n",
    "        if len(data.shape) == 2: \n",
    "            data = data[:, 0]\n",
    "            \n",
    "\n",
    "        # Normalize the data\n",
    "        data = data / np.max(np.abs(data))\n",
    "\n",
    "        # # Perform VMD\n",
    "        modes, residual, _ = VMD_torch(\n",
    "            f = data, \n",
    "            alpha=data.shape[0],  # adjust as needed\n",
    "            tau=0,       # noise-slack\n",
    "            K=8,         # number of modes\n",
    "            DC=False,     # keep zero frequency mode\n",
    "            init=1,      # uniformly distributed initial omegas\n",
    "            tol=1e-30     # convergence tolerance\n",
    "        )\n",
    "\n",
    "        # # Save the decomposed modes and reconstructed signal\n",
    "        # save_modes_and_reconstruct(modes, residual, sample_rate, data, base_filename)\n",
    "\n",
    "        # print(f\"Processed {base_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    # Extract and clean the relative path\n",
    "    relative_path = row['AudioPath'].strip()\n",
    "    \n",
    "    if relative_path.startswith('../data/audios/'):\n",
    "        relative_path = relative_path.replace('../data/audios/', '')\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(audio_directory, relative_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Read the audio file\n",
    "        sample_rate, data = wavfile.read(file_path)\n",
    "\n",
    "        # Convert stereo to mono if needed\n",
    "        if len(data.shape) == 2: \n",
    "            data = data[:, 0]\n",
    "            \n",
    "\n",
    "        # Normalize the data\n",
    "        data = data / np.max(np.abs(data))\n",
    "\n",
    "        # # Perform VMD\n",
    "        modes, residual, _ = VMD_torch(\n",
    "            f = data, \n",
    "            alpha=data.shape[0],  # adjust as needed\n",
    "            tau=0,       # noise-slack\n",
    "            K=8,         # number of modes\n",
    "            DC=False,     # keep zero frequency mode\n",
    "            init=1,      # uniformly distributed initial omegas\n",
    "            tol=1e-30     # convergence tolerance\n",
    "        )\n",
    "\n",
    "        # # Save the decomposed modes and reconstructed signal\n",
    "        # save_modes_and_reconstruct(modes, residual, sample_rate, data, base_filename)\n",
    "\n",
    "        # print(f\"Processed {base_filename}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Directory containing subfolders with audio files\n",
    "audio_directory = r\"C:\\Users\\Asus\\OneDrive - Amrita Vishwa Vidyapeetham\\Desktop\\biorun\\IMFs\\IMFS_VMD\"\n",
    "\n",
    "# Directory to save Mel spectrograms\n",
    "spectrogram_directory = r\"C:\\Users\\Asus\\OneDrive - Amrita Vishwa Vidyapeetham\\Desktop\\biorun\\Spectrograms\\VMD_S\"\n",
    "\n",
    "# Create the spectrogram directory if it doesn't exist\n",
    "if not os.path.exists(spectrogram_directory):\n",
    "    os.makedirs(spectrogram_directory)\n",
    "\n",
    "# Function to compute and save Mel spectrogram\n",
    "def save_mel_spectrogram(audio_data, sample_rate, output_path):\n",
    "    # Compute the Mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "\n",
    "    # Convert power spec to dB for visualization\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Plot the Mel spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mel_spectrogram_db, sr=sample_rate, x_axis='time', y_axis='mel', fmax=8000)\n",
    "\n",
    "    # Remove the title, axis labels, and color bar\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "# Function to process each audio file in the subfolders\n",
    "def process_audio_file(row):\n",
    "    \"\"\"\n",
    "    Process each audio file for VMD and generate Mel spectrogram.\n",
    "    \n",
    "    Parameters:\n",
    "        row (dict): A dictionary containing audio file metadata (e.g., path).\n",
    "    \"\"\"\n",
    "    # Extract and clean the relative path\n",
    "    relative_path = row['AudioPath'].strip()\n",
    "    if relative_path.startswith('../data/audios/'):\n",
    "        relative_path = relative_path.replace('../data/audios/', '')\n",
    "\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(audio_directory, relative_path)\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    try:\n",
    "        # Read the audio file\n",
    "        sample_rate, data = wavfile.read(file_path)\n",
    "\n",
    "        # Convert stereo to mono if needed\n",
    "        if len(data.shape) == 2: \n",
    "            data = data[:, 0]\n",
    "\n",
    "        # Normalize the data\n",
    "        data = data / np.max(np.abs(data))\n",
    "\n",
    "        # Create a folder to save the Mel spectrograms for this specific subfolder\n",
    "        subfolder_name = os.path.basename(os.path.dirname(file_path))\n",
    "        output_folder = os.path.join(spectrogram_directory, subfolder_name)\n",
    "\n",
    "        # Create the subfolder if it doesn't exist\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        # Create the output file path for the Mel spectrogram\n",
    "        spectrogram_file_name = base_filename + '_mel_spectrogram.png'\n",
    "        spectrogram_file_path = os.path.join(output_folder, spectrogram_file_name)\n",
    "\n",
    "        # Compute and save Mel spectrogram\n",
    "        save_mel_spectrogram(data, sample_rate, spectrogram_file_path)\n",
    "\n",
    "        print(f\"Mel Spectrogram saved: {spectrogram_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Iterate through each subfolder and audio file\n",
    "for root, dirs, files in os.walk(audio_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            # Construct the relative path for the file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), audio_directory)\n",
    "            row = {'AudioPath': relative_path}\n",
    "            \n",
    "            # Process the audio file\n",
    "            process_audio_file(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fft\n",
    "\n",
    "def vmd(signal, alpha=2000, tau=0, K=5, DC=0, init=None, tol=1e-6, device='cuda'):\n",
    "    \"\"\"\n",
    "    GPU-accelerated Variational Mode Decomposition (VMD)\n",
    "    \n",
    "    Args:\n",
    "        signal: Input signal (1D tensor).\n",
    "        alpha: Regularization parameter.\n",
    "        tau: Time step for dual ascent.\n",
    "        K: Number of modes.\n",
    "        DC: 0 for no DC component, 1 otherwise.\n",
    "        init: Initial values for modes and Lagrange multiplier.\n",
    "        tol: Convergence tolerance.\n",
    "        device: 'cuda' for GPU acceleration, 'cpu' otherwise.\n",
    "    \n",
    "    Returns:\n",
    "        modes: Decomposed modes (K x N tensor).\n",
    "    \"\"\"\n",
    "    # Move input signal to device\n",
    "    signal = torch.tensor(signal, dtype=torch.float32, device=device)\n",
    "    N = len(signal)\n",
    "    \n",
    "    # Fourier transform of the input signal\n",
    "    f_signal = torch.fft.fft(signal)\n",
    "    omega = torch.fft.fftfreq(N, d=1.0)\n",
    "    omega = omega.to(device)\n",
    "    \n",
    "    # Initialization\n",
    "    if init is None:\n",
    "        u = torch.zeros((K, N), device=device, dtype=torch.complex64)\n",
    "        omega_k = torch.linspace(0, torch.max(omega), K, device=device)\n",
    "    else:\n",
    "        u, omega_k = init\n",
    "    \n",
    "    # Lagrange multiplier\n",
    "    lambda_hat = torch.zeros(N, device=device, dtype=torch.complex64)\n",
    "    \n",
    "    # Dual ascent iterations\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        u_prev = u.clone()\n",
    "        \n",
    "        # Update each mode\n",
    "        for k in range(K):\n",
    "            # Construct denominator term\n",
    "            omega_shifted = omega - omega_k[k]\n",
    "            denominator = 1 + alpha * (omega_shifted ** 2)\n",
    "            \n",
    "            # Compute mode in Fourier domain\n",
    "            f_u_k = (f_signal - lambda_hat - torch.sum(u, dim=0) + u[k]) / denominator\n",
    "            u[k] = torch.fft.ifft(f_u_k).real\n",
    "        \n",
    "        # Update omega_k\n",
    "        for k in range(K):\n",
    "            omega_k[k] = torch.sum(torch.abs(u[k]) ** 2 * omega) / torch.sum(torch.abs(u[k]) ** 2)\n",
    "        \n",
    "        # Update Lagrange multiplier\n",
    "        residual = signal - torch.sum(u, dim=0).real\n",
    "        lambda_hat += tau * torch.fft.fft(residual)\n",
    "        \n",
    "        # Check convergence\n",
    "        if torch.norm(u - u_prev) < tol:\n",
    "            break\n",
    "        iteration += 1\n",
    "        if iteration > 500:  # Prevent infinite loops\n",
    "            break\n",
    "    \n",
    "    return u.real.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Generate synthetic signal\n",
    "    t = np.linspace(0, 1, 1000)\n",
    "    signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "    \n",
    "    # Run GPU-accelerated VMD\n",
    "    modes = vmd(signal, K=5, device='cuda')\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    plt.plot(t, signal, label=\"Original Signal\")\n",
    "    for i, mode in enumerate(modes):\n",
    "        plt.plot(t, mode, label=f\"Mode {i+1}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from vmdpy import VMD\n",
    "import torch\n",
    "import torch.fft\n",
    "\n",
    "# VMDPy (CPU-based)\n",
    "def vmdpy_vmd(signal, alpha=2000, tau=0, K=5, DC=0, tol=1e-6):\n",
    "    \"\"\"\n",
    "    VMD using the vmdpy library (CPU implementation).\n",
    "    \"\"\"\n",
    "    u, a, b = VMD(signal, alpha, tau, K, DC, init=1, tol=tol)\n",
    "    return u, a, b\n",
    "\n",
    "# GPU-Accelerated VMD\n",
    "def gpu_vmd(signal, alpha=2000, tau=0, K=5, DC=0, tol=1e-6, device='cuda'):\n",
    "    signal = torch.tensor(signal, dtype=torch.float32, device=device)\n",
    "    N = len(signal)\n",
    "    f_signal = torch.fft.fft(signal)\n",
    "    omega = torch.fft.fftfreq(N, d=1.0).to(device)\n",
    "\n",
    "    u = torch.zeros((K, N), device=device, dtype=torch.complex64)\n",
    "    omega_k = torch.linspace(0, torch.max(omega), K, device=device)\n",
    "    lambda_hat = torch.zeros(N, device=device, dtype=torch.complex64)\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        u_prev = u.clone()\n",
    "        for k in range(K):\n",
    "            omega_shifted = omega - omega_k[k]\n",
    "            denominator = 1 + alpha * (omega_shifted ** 2)\n",
    "            f_u_k = (f_signal - lambda_hat - torch.sum(u, dim=0) + u[k]) / denominator\n",
    "            u[k] = torch.fft.ifft(f_u_k).real\n",
    "        for k in range(K):\n",
    "            omega_k[k] = torch.sum(torch.abs(u[k]) ** 2 * omega) / torch.sum(torch.abs(u[k]) ** 2)\n",
    "        residual = signal - torch.sum(u, dim=0).real\n",
    "        lambda_hat += tau * torch.fft.fft(residual)\n",
    "        if torch.norm(u - u_prev) < tol or iteration > 500:\n",
    "            break\n",
    "        iteration += 1\n",
    "\n",
    "    return u.real.cpu().detach().numpy()\n",
    "\n",
    "def pad_signal(original, reconstructed):\n",
    "    if len(reconstructed) < len(original):\n",
    "        padding = len(original) - len(reconstructed)\n",
    "        reconstructed = np.pad(reconstructed, (0, padding), mode='constant', constant_values=0)\n",
    "    elif len(reconstructed) > len(original):\n",
    "        reconstructed = reconstructed[:len(original)]\n",
    "    return reconstructed\n",
    "\n",
    "# Benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from scipy.io import wavfile\n",
    "    from VMD.main import GPU_VMD\n",
    "    \n",
    "    signal = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0036.wav')[1]\n",
    "\n",
    "    # Generate a synthetic signal\n",
    "    t = np.linspace(0, 1, len(signal))\n",
    "    # signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "    print(\"signal len\", len(signal))\n",
    "    # VMDPy\n",
    "    start_time = time.time()\n",
    "    modes_vmdpy, a ,b = vmdpy_vmd(signal, alpha=200000, tau=0, K=8, DC=False, tol=1e-70)\n",
    "    vmdpy_time = time.time() - start_time\n",
    "\n",
    "    # GPU-Accelerated VMD\n",
    "    # Initialize VMD\n",
    "    vmd = GPU_VMD(\n",
    "        alpha=200000,  # Bandwidth constraint\n",
    "        tau=0,       # Noise-tolerance\n",
    "        n_modes=8,   # Number of modes to extract\n",
    "        dc_component=False,  # Whether to force first mode to be DC\n",
    "        init_method=1,      # Frequency initialization method\n",
    "        tolerance=1e-6,     # Convergence tolerance\n",
    "        device='cuda'       # Computing device\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    # Decompose signal\n",
    "    result = vmd.decompose(signal)\n",
    "    \n",
    "    \n",
    "    modes_gpu = result.modes\n",
    "\n",
    "    \n",
    "\n",
    "    gpu_time = time.time() - start_time\n",
    "\n",
    "    # Calculate reconstruction error\n",
    "    reconstructed_vmdpy = np.sum(modes_vmdpy, axis=0)\n",
    "    reconstructed_gpu = np.sum(modes_gpu, axis=0)\n",
    "\n",
    "    # Pad the reconstructed signals\n",
    "    reconstructed_vmdpy_padded = pad_signal(signal, reconstructed_vmdpy)\n",
    "    reconstructed_gpu_padded = pad_signal(signal, reconstructed_gpu)\n",
    "\n",
    "    # Calculate mean squared errors\n",
    "    mse_vmdpy = mean_squared_error(signal, reconstructed_vmdpy_padded)\n",
    "    mse_gpu = mean_squared_error(signal, reconstructed_gpu_padded)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"VMDPy (CPU): Time = {vmdpy_time:.4f}s, MSE = {mse_vmdpy:.4e}\")\n",
    "    print(f\"GPU-Accelerated VMD: Time = {gpu_time:.4f}s, MSE = {mse_gpu:.4e}\")\n",
    "\n",
    "    # Plot VMDPy results (separate modes)\n",
    "    plt.figure(figsize=(25, 18))\n",
    "    plt.suptitle(\"Decomposed Modes: VMDPy (CPU Implementation)\", fontsize=16)\n",
    "    for i, mode in enumerate(modes_vmdpy):\n",
    "        plt.subplot(len(modes_vmdpy), 1, i + 1)\n",
    "        plt.plot(t, pad_signal(signal, mode), label=f\"VMDPy Mode {i+1}\", color='blue')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # Plot GPU-Accelerated VMD results (separate modes)\n",
    "    plt.figure(figsize=(25, 18))\n",
    "    plt.suptitle(\"Decomposed Modes: GPU-Accelerated VMD\", fontsize=16)\n",
    "    for i, mode in enumerate(modes_gpu):\n",
    "        plt.subplot(len(modes_gpu), 1, i + 1)\n",
    "        plt.plot(t, pad_signal(signal, mode), label=f\"GPU Mode {i+1}\", color='green')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from vmdpy import VMD\n",
    "import torch\n",
    "import torch.fft\n",
    "\n",
    "# VMDPy (CPU-based)\n",
    "def vmdpy_vmd(signal, alpha=2000, tau=0, K=5, DC=0, tol=1e-6):\n",
    "    \"\"\"\n",
    "    VMD using the vmdpy library (CPU implementation).\n",
    "    \"\"\"\n",
    "    u, a, b = VMD(signal, alpha, tau, K, DC, init=1, tol=tol)\n",
    "    return u, a, b\n",
    "\n",
    "# GPU-Accelerated VMD\n",
    "def gpu_vmd(signal, alpha=2000, tau=0, K=5, DC=0, tol=1e-6, device='cuda'):\n",
    "    signal = torch.tensor(signal, dtype=torch.float32, device=device)\n",
    "    N = len(signal)\n",
    "    f_signal = torch.fft.fft(signal)\n",
    "    omega = torch.fft.fftfreq(N, d=1.0).to(device)\n",
    "\n",
    "    u = torch.zeros((K, N), device=device, dtype=torch.complex64)\n",
    "    omega_k = torch.linspace(0, torch.max(omega), K, device=device)\n",
    "    lambda_hat = torch.zeros(N, device=device, dtype=torch.complex64)\n",
    "\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        u_prev = u.clone()\n",
    "        for k in range(K):\n",
    "            omega_shifted = omega - omega_k[k]\n",
    "            denominator = 1 + alpha * (omega_shifted ** 2)\n",
    "            f_u_k = (f_signal - lambda_hat - torch.sum(u, dim=0) + u[k]) / denominator\n",
    "            u[k] = torch.fft.ifft(f_u_k).real\n",
    "        for k in range(K):\n",
    "            omega_k[k] = torch.sum(torch.abs(u[k]) ** 2 * omega) / torch.sum(torch.abs(u[k]) ** 2)\n",
    "        residual = signal - torch.sum(u, dim=0).real\n",
    "        lambda_hat += tau * torch.fft.fft(residual)\n",
    "        if torch.norm(u - u_prev) < tol or iteration > 500:\n",
    "            break\n",
    "        iteration += 1\n",
    "\n",
    "    return u.real.cpu().detach().numpy()\n",
    "\n",
    "def pad_signal(original, reconstructed):\n",
    "    if len(reconstructed) < len(original):\n",
    "        padding = len(original) - len(reconstructed)\n",
    "        reconstructed = np.pad(reconstructed, (0, padding), mode='constant', constant_values=0)\n",
    "    elif len(reconstructed) > len(original):\n",
    "        reconstructed = reconstructed[:len(original)]\n",
    "    return reconstructed\n",
    "\n",
    "# Benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from scipy.io import wavfile\n",
    "    \n",
    "    signal = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')[1]\n",
    "\n",
    "    # Generate a synthetic signal\n",
    "    t = np.linspace(0, 1, len(signal))\n",
    "    # signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "    print(\"signal len\", len(signal))\n",
    "    # VMDPy\n",
    "    start_time = time.time()\n",
    "    modes_vmdpy, a ,b = vmdpy_vmd(signal, alpha=200000, tau=0, K=7, DC=False, tol=1e-70)\n",
    "    vmdpy_time = time.time() - start_time\n",
    "\n",
    "    # GPU-Accelerated VMD\n",
    "    start_time = time.time()\n",
    "    modes_gpu, c,d = VMD_torch(\n",
    "    f = signal, \n",
    "    alpha=200000,  # adjust as needed\n",
    "    tau=0,       # noise-slack\n",
    "    K=7,         # number of modes\n",
    "    DC=False,     # keep zero frequency mode\n",
    "    init=1,      # uniformly distributed initial omegas\n",
    "    tol=1e-70     # convergence tolerance\n",
    ")\n",
    "    \n",
    "    # modes_gpu = np.insert(modes_gpu, 3, modes_gpu[-1], axis=0)[:-1]\n",
    "    #f, alpha, tau, K, DC, init, tol, device=\"cuda\"\n",
    "    gpu_time = time.time() - start_time\n",
    "\n",
    "    # Calculate reconstruction error\n",
    "    reconstructed_vmdpy = np.sum(modes_vmdpy, axis=0)\n",
    "    reconstructed_gpu = np.sum(modes_gpu, axis=0)\n",
    "\n",
    "    # Pad the reconstructed signals\n",
    "    reconstructed_vmdpy_padded = pad_signal(signal, reconstructed_vmdpy)\n",
    "    reconstructed_gpu_padded = pad_signal(signal, reconstructed_gpu)\n",
    "\n",
    "    # Calculate mean squared errors\n",
    "    mse_vmdpy = mean_squared_error(signal, reconstructed_vmdpy_padded)\n",
    "    mse_gpu = mean_squared_error(signal, reconstructed_gpu_padded)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"VMDPy (CPU): Time = {vmdpy_time:.4f}s, MSE = {mse_vmdpy:.4e}\")\n",
    "    print(f\"GPU-Accelerated VMD: Time = {gpu_time:.4f}s, MSE = {mse_gpu:.4e}\")\n",
    "\n",
    "    # Plot VMDPy results (separate modes)\n",
    "    plt.figure(figsize=(25, 18))\n",
    "    plt.suptitle(\"Decomposed Modes: VMDPy (CPU Implementation)\", fontsize=16)\n",
    "    for i, mode in enumerate(modes_vmdpy):\n",
    "        plt.subplot(len(modes_vmdpy), 1, i + 1)\n",
    "        plt.plot(t, pad_signal(signal, mode), label=f\"VMDPy Mode {i+1}\", color='blue')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "    # Plot GPU-Accelerated VMD results (separate modes)\n",
    "    plt.figure(figsize=(25, 18))\n",
    "    plt.suptitle(\"Decomposed Modes: GPU-Accelerated VMD\", fontsize=16)\n",
    "    for i, mode in enumerate(modes_gpu):\n",
    "        plt.subplot(len(modes_gpu), 1, i + 1)\n",
    "        plt.plot(t, pad_signal(signal, mode), label=f\"GPU Mode {i+1}\", color='green')\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Amplitude\")\n",
    "        plt.grid(True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VMDPy results (separate modes)\n",
    "plt.figure(figsize=(25, 18))\n",
    "plt.suptitle(\"Decomposed Modes: VMDPy (CPU Implementation)\", fontsize=16)\n",
    "for i, mode in enumerate(modes_vmdpy):\n",
    "    plt.subplot(len(modes_vmdpy), 1, i + 1)\n",
    "    plt.plot(t[:2000], pad_signal(signal[:2000], mode[:2000]), label=f\"VMDPy Mode {i+1}\", color='blue')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Plot GPU-Accelerated VMD results (separate modes)\n",
    "plt.figure(figsize=(25, 18))\n",
    "plt.suptitle(\"Decomposed Modes: GPU-Accelerated VMD\", fontsize=16)\n",
    "for i, mode in enumerate(modes_gpu):\n",
    "    plt.subplot(len(modes_gpu), 1, i + 1)\n",
    "    plt.plot(t[:2000], pad_signal(signal[:2000], mode[:2000]), label=f\"GPU Mode {i+1}\", color='green')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "# Sample input: Replace 'modes' with your numpy.ndarray\n",
    "# modes = np.random.randn(8, 1000)  # Example: 8 IMFs with 1000 samples each\n",
    "\n",
    "def dominant_frequency_sort(modes, sampling_rate=1.0):\n",
    "    \"\"\"\n",
    "    Sort modes by their dominant frequency.\n",
    "    \n",
    "    :param modes: numpy.ndarray of shape (n_modes, n_samples)\n",
    "    :param sampling_rate: Sampling rate of the signal (default: 1.0)\n",
    "    :return: Modes sorted by dominant frequency (descending order)\n",
    "    \"\"\"\n",
    "    dominant_frequencies = []\n",
    "    n_samples = modes.shape[1]\n",
    "    \n",
    "    for mode in modes:\n",
    "        # Compute FFT and frequency spectrum\n",
    "        freqs = np.fft.fftfreq(n_samples, d=1/sampling_rate)\n",
    "        fft_values = np.abs(fft(mode))\n",
    "        \n",
    "        # Get positive frequencies and their corresponding FFT values\n",
    "        positive_freqs = freqs[:n_samples // 2]\n",
    "        positive_fft_values = fft_values[:n_samples // 2]\n",
    "        \n",
    "        # Find dominant frequency\n",
    "        dominant_freq = positive_freqs[np.argmax(positive_fft_values)]\n",
    "        dominant_frequencies.append(dominant_freq)\n",
    "    \n",
    "    # Sort indices by dominant frequencies\n",
    "    print(dominant_frequencies)\n",
    "    sorted_indices = np.argsort(dominant_frequencies)[::-1]  # Descending order\n",
    "    return modes[sorted_indices], sorted_indices\n",
    "\n",
    "# Example usage\n",
    "sorted_modes, indices = dominant_frequency_sort(modes_gpu, sampling_rate=1000)\n",
    "# print(\"Sorted Modes:\", sorted_modes)\n",
    "print(\"Indices:\", indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GPU-Accelerated VMD results (separate modes)\n",
    "plt.figure(figsize=(25, 18))\n",
    "plt.suptitle(\"Decomposed Modes: GPU-Accelerated VMD\", fontsize=16)\n",
    "for i, mode in enumerate(sorted_modes[::-1]):\n",
    "    plt.subplot(len(modes_gpu), 1, i + 1)\n",
    "    plt.plot(t, pad_signal(signal, mode), label=f\"GPU Mode {i+1}\", color='green')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(modes_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav', sr=None)\n",
    "\n",
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "librosa.display.specshow(stft_magnitude,\n",
    "                         sr=sr, hop_length=512, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('STFT Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "librosa.display.specshow(stft_magnitude, sr=sr, hop_length=512, y_axis='log', x_axis='time', ax=ax, cmap='gray')\n",
    "\n",
    "# Remove the axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Remove the borders and save the image\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Adjust to remove padding\n",
    "# plt.savefig(\"spectrogram.png\", bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "plt.show()\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "canvas = FigureCanvas(fig)\n",
    "canvas.draw()\n",
    "\n",
    "width, height = canvas.get_width_height()9090\n",
    "image = np.frombuffer(canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 1)\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a.delaxes()).savefig(r'C:\\Users\\Arun\\parkinson-s-classify\\HC_A1_0034.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav', sr=None)\n",
    "\n",
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n",
    "\n",
    "# Convert to decibel scale\n",
    "spectrogram_db = librosa.amplitude_to_db(stft_magnitude, ref=np.max)\n",
    "\n",
    "# Resize the spectrogram to 224x224\n",
    "resized_spectrogram = resize(spectrogram_db, (224, 224), anti_aliasing=True)\n",
    "\n",
    "# Plot the original spectrogram\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.specshow(spectrogram_db, sr=sr, hop_length=512, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original STFT Spectrogram')\n",
    "\n",
    "# Plot the resized spectrogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(resized_spectrogram, origin='lower', aspect='auto', cmap='magma')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Resized Spectrogram (224x224)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: If you want to save the resized spectrogram as an image\n",
    "import matplotlib.image as mpimg\n",
    "mpimg.imsave('resized_spectrogram.png', resized_spectrogram, cmap='magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_magnitude.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\Outputs\\Reconstructed\\HC_A1_0034_reconstructed.wav', sr=None)\n",
    "\n",
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n",
    "\n",
    "# Convert to decibel scale\n",
    "spectrogram_db = librosa.amplitude_to_db(stft_magnitude, ref=np.max)\n",
    "\n",
    "# Resize the spectrogram to 224x224\n",
    "resized_spectrogram = resize(spectrogram_db, (224, 224), anti_aliasing=True)\n",
    "\n",
    "# Plot the original spectrogram\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.specshow(spectrogram_db, sr=sr, hop_length=512, y_axis='mel', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original STFT Spectrogram')\n",
    "\n",
    "# Plot the resized spectrogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(resized_spectrogram, origin='lower', aspect='auto', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Resized Spectrogram (224x224)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: If you want to save the resized spectrogram as an image\n",
    "# import matplotlib.image as mpimg\n",
    "# mpimg.imsave('resized_spectrogram.png', resized_spectrogram, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav', sr=None)\n",
    "\n",
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n",
    "\n",
    "# Convert to decibel scale (log scale)\n",
    "spectrogram_db = librosa.amplitude_to_db(stft_magnitude, ref=np.max)\n",
    "\n",
    "# Original frequency values (Hz)\n",
    "freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)\n",
    "\n",
    "# Target log-scaled frequency bins\n",
    "log_freqs = np.geomspace(freqs[1], freqs[-1], num=224)\n",
    "\n",
    "# Interpolate to map original spectrogram to new log scale\n",
    "interpolator = interp1d(freqs, spectrogram_db, axis=0, bounds_error=False, fill_value=-80)\n",
    "log_spectrogram = interpolator(log_freqs)\n",
    "\n",
    "# Plot the original spectrogram\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "librosa.display.specshow(spectrogram_db, sr=sr, hop_length=512, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Original Log-Scale Spectrogram')\n",
    "\n",
    "# Plot the resized spectrogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(log_spectrogram, origin='lower', aspect='auto', cmap='magma',\n",
    "           extent=[0, spectrogram_db.shape[1] * (512 / sr), log_freqs[0], log_freqs[-1]])\n",
    "plt.yscale('log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Resized Log-Scale Spectrogram (224x224)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav', sr=None)\n",
    "\n",
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(stft_magnitude, ref=np.max),\n",
    "                         sr=sr, hop_length=512, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('STFT Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load speech signal\n",
    "signal, sr = librosa.load(r'C:\\Users\\Arun\\parkinson-s-classify\\VMD\\filtered_speech.wav', sr=None)\n",
    "\n",
    "# Compute STFT\n",
    "stft_result = librosa.stft(signal, n_fft=2048, hop_length=512)\n",
    "# Compute magnitude\n",
    "stft_magnitude = np.abs(stft_result)\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(stft_magnitude, ref=np.max),\n",
    "                         sr=sr, hop_length=512, y_axis='log', x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('STFT Spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft\n",
    "\n",
    "# Step 1: Read the audio file\n",
    "samplerate, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "\n",
    "# Ensure the audio is mono (convert if necessary)\n",
    "if data.ndim > 1:\n",
    "    data = data.mean(axis=1)\n",
    "\n",
    "# Step 2: Apply STFT\n",
    "# Define parameters for STFT\n",
    "nperseg = 1024  # Length of each segment\n",
    "f, t, Zxx = stft(data, fs=samplerate, nperseg=nperseg)\n",
    "\n",
    "# Step 3: Filter frequencies up to 1000 Hz\n",
    "freq_limit = 4000\n",
    "freq_indices = f <= freq_limit\n",
    "f_filtered = f[freq_indices]\n",
    "Zxx_filtered = Zxx[freq_indices, :]\n",
    "\n",
    "# Step 4: Plot the spectrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pcolormesh(t, f_filtered, np.abs(Zxx_filtered), shading='gouraud', cmap='inferno')\n",
    "plt.title('Spectrogram (STFT) - Frequencies up to 1000 Hz')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "def VMD_GPU(f, alpha, tau, K, DC=False, init=0, tol=1e-6):\n",
    "    \"\"\"\n",
    "    GPU-Accelerated Variational Mode Decomposition\n",
    "    \"\"\"\n",
    "    # Ensure input is on GPU and convert to single precision\n",
    "    f = cp.asarray(f, dtype=cp.float64)\n",
    "    \n",
    "    if len(f) % 2:\n",
    "        f = f[:-1]\n",
    "\n",
    "    # Period and sampling frequency of input signal\n",
    "    fs = cp.float32(1. / len(f))\n",
    "    \n",
    "    ltemp = len(f) // 2 \n",
    "    fMirr = cp.concatenate([cp.flip(f[:ltemp]), f, cp.flip(f[-ltemp:])])\n",
    "\n",
    "    # Time Domain\n",
    "    T = len(fMirr)\n",
    "    t = cp.arange(0, T, dtype=cp.float32) / T\n",
    "    \n",
    "    # Spectral Domain discretization\n",
    "    freqs = cp.fft.fftshift(cp.fft.fftfreq(T, d=1.0))\n",
    "\n",
    "    # Maximum number of iterations\n",
    "    Niter = 500\n",
    "    # Individual alpha for each mode\n",
    "    Alpha = cp.full(K, alpha, dtype=cp.float32)\n",
    "    \n",
    "    # Construct and center f_hat\n",
    "    f_hat = cp.fft.fftshift(cp.fft.fft(fMirr.astype(cp.complex64)))\n",
    "    f_hat_plus = f_hat.copy()\n",
    "    f_hat_plus[:T//2] = 0\n",
    "\n",
    "    # Initialization of omega_k\n",
    "    omega_plus = cp.zeros((Niter, K), dtype=cp.float32)\n",
    "\n",
    "    if init == 1:\n",
    "        omega_plus[0, :] = cp.linspace(0, 0.5, K, dtype=cp.float32)\n",
    "    elif init == 2:\n",
    "        omega_plus[0, :] = cp.sort(cp.exp(cp.log(fs) + (cp.log(0.5) - cp.log(fs)) * cp.random.rand(K, dtype=cp.float32)))\n",
    "    else:\n",
    "        omega_plus[0, :] = 0\n",
    "            \n",
    "    # if DC mode imposed, set its omega to 0\n",
    "    if DC:\n",
    "        omega_plus[0, 0] = 0\n",
    "    \n",
    "    # Start with empty dual variables\n",
    "    lambda_hat = cp.zeros((Niter, len(freqs)), dtype=cp.complex64)\n",
    "    \n",
    "    # Other initializations\n",
    "    uDiff = tol + cp.finfo(cp.float32).eps\n",
    "    n = 0\n",
    "    sum_uk = 0\n",
    "    u_hat_plus = cp.zeros((Niter, len(freqs), K), dtype=cp.complex64)\n",
    "\n",
    "    # Main loop for iterative updates\n",
    "    while (uDiff > tol and n < Niter - 1):\n",
    "        # Update first mode accumulator\n",
    "        k = 0\n",
    "        sum_uk = u_hat_plus[n, :, K-1] + sum_uk - u_hat_plus[n, :, 0]\n",
    "        \n",
    "        # Update spectrum of first mode\n",
    "        u_hat_plus[n + 1, :, k] = (f_hat_plus - sum_uk - lambda_hat[n, :] / 2) / \\\n",
    "                                  (1 + Alpha[k] * (freqs - omega_plus[n, k]) ** 2)\n",
    "        \n",
    "        # Update omega if not held at 0\n",
    "        if not DC:\n",
    "            omega_plus[n + 1, k] = cp.dot(\n",
    "                freqs[T//2:T], cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2) / \\\n",
    "                cp.sum(cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2)\n",
    "\n",
    "        # Update any other mode\n",
    "        for k in range(1, K):\n",
    "            sum_uk = u_hat_plus[n + 1, :, k - 1] + sum_uk - u_hat_plus[n, :, k]\n",
    "            u_hat_plus[n + 1, :, k] = (f_hat_plus - sum_uk - lambda_hat[n, :] / 2) / \\\n",
    "                                      (1 + Alpha[k] * (freqs - omega_plus[n, k]) ** 2)\n",
    "            omega_plus[n + 1, k] = cp.dot(\n",
    "                freqs[T//2:T], cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2) / \\\n",
    "                cp.sum(cp.abs(u_hat_plus[n + 1, T//2:T, k]) ** 2)\n",
    "            \n",
    "        # Dual ascent\n",
    "        lambda_hat[n + 1, :] = lambda_hat[n, :] + tau * (cp.sum(u_hat_plus[n + 1, :, :], axis=1) - f_hat_plus)\n",
    "        \n",
    "        # Update loop counter and check for convergence\n",
    "        n += 1\n",
    "        uDiff = cp.sum(cp.abs(u_hat_plus[n, :, :] - u_hat_plus[n - 1, :, :]) ** 2).get()\n",
    "            \n",
    "    # Postprocessing and cleanup\n",
    "    Niter = min(Niter, n)\n",
    "    omega = omega_plus[:Niter, :].astype(cp.float32)\n",
    "    \n",
    "    # Reconstruct modes\n",
    "    u_hat = cp.zeros((T, K), dtype=cp.complex64)\n",
    "    u_hat[T//2:T, :] = u_hat_plus[Niter - 1, T//2:T, :]\n",
    "    u_hat[:T//2, :] = cp.conj(u_hat_plus[Niter - 1, T//2:T, :])\n",
    "    \n",
    "    u = cp.zeros((K, len(t)), dtype=cp.float32)\n",
    "    for k in range(K):\n",
    "        u_k = cp.real(cp.fft.ifft(cp.fft.ifftshift(u_hat[:, k])))\n",
    "        # Apply proper window function to reduce edge effects\n",
    "        window = cp.hanning(len(u_k))\n",
    "        u[k, :] = u_k * window\n",
    "    \n",
    "    # 6. Final trimming - ensure proper alignment with original signal\n",
    "    mid_point = len(u[0]) // 2\n",
    "    half_len = len(f) // 2\n",
    "    u = u[:, mid_point-half_len:mid_point+half_len]\n",
    "    \n",
    "    return u.get(), u_hat.get(), omega.get()\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def test_vmd_gpu():\n",
    "    # Generate a sample signal\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a sample signal with multiple modes\n",
    "    t = np.linspace(0, 1, 1000)\n",
    "    signal = (np.sin(2 * np.pi * 10 * t) +  # 10 Hz component\n",
    "              0.5 * np.sin(2 * np.pi * 20 * t) +  # 20 Hz component\n",
    "              0.25 * np.random.normal(size=t.shape))  # some noise\n",
    "    \n",
    "    # Decompose the signal\n",
    "    modes, mode_spectra, mode_frequencies = VMD_GPU(\n",
    "        signal, \n",
    "        alpha=2000,  # high alpha for tight mode bounds\n",
    "        tau=0,       # noise-slack\n",
    "        K=3,         # number of modes to extract\n",
    "        DC=True,     # keep zero frequency mode\n",
    "        init=1,      # uniformly distributed initial omegas\n",
    "        tol=1e-6     # convergence tolerance\n",
    "    )\n",
    "    \n",
    "    return modes, mode_spectra, mode_frequencies\n",
    "\n",
    "# Uncomment to run the test\n",
    "# modes, spectra, frequencies = test_vmd_gpu()\n",
    "\n",
    "# Optional visualization function\n",
    "def plot_vmd_modes(t, signal, modes):\n",
    "    \"\"\"\n",
    "    Plot the original signal and the decomposed modes.\n",
    "    \n",
    "    Parameters:\n",
    "    t (numpy array): Time values\n",
    "    signal (numpy array): Original signal\n",
    "    modes (list of numpy arrays): Decomposed modes\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(25, 4))\n",
    "    plt.plot(t, signal, label=\"Original Signal\", color='black')\n",
    "    plt.plot(t, signal - np.sum(modes, axis=0), label=\"Residual Signal\", color='red')\n",
    "    \n",
    "    for i, mode in enumerate(modes):\n",
    "        plt.plot(t, mode, label=f\"VMDPy Mode {i+1}\", linewidth=1)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(\"Decomposed Modes: VMDPy (CPU Implementation)\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate or load your signal\n",
    "# t = np.linspace(0, 1, 1000)\n",
    "# signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 20 * t) + 0.25 * np.random.normal(size=t.shape)\n",
    "t = np.linspace(0, 1, 200000)\n",
    "signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "# Decompose the signal\n",
    "modes, mode_spectra, mode_frequencies = VMD(\n",
    "    signal, \n",
    "    alpha=200000,  # adjust as needed\n",
    "    tau=0,       # noise-slack\n",
    "    K=2,         # number of modes\n",
    "    DC=False,     # keep zero frequency mode\n",
    "    init=2,      # uniformly distributed initial omegas\n",
    "    tol=1e-30     # convergence tolerance\n",
    ")\n",
    "\n",
    "# Optional: Visualize the modes\n",
    "plot_vmd_modes(t, signal, modes,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate or load your signal\n",
    "# t = np.linspace(0, 1, 1000)\n",
    "# signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 20 * t) + 0.25 * np.random.normal(size=t.shape)\n",
    "t = np.linspace(0, 1, 200000)\n",
    "signal = np.sin(2 * np.pi * 10 * t) + 0.5 * np.sin(2 * np.pi * 50 * t)\n",
    "# Decompose the signal\n",
    "vmd = GPU_VMD(\n",
    "        alpha=200000,  # Bandwidth constraint\n",
    "        tau=0,       # Noise-tolerance\n",
    "        n_modes=2,   # Number of modes to extract\n",
    "        dc_component=False,  # Whether to force first mode to be DC\n",
    "        init_method=1,      # Frequency initialization method\n",
    "        tolerance=1e-6,     # Convergence tolerance\n",
    "        device='cuda'       # Computing device\n",
    "    )\n",
    "# Decompose signal\n",
    "result = vmd.decompose(signal)\n",
    "\n",
    "\n",
    "modes = result.modes\n",
    "\n",
    "# Optional: Visualize the modes\n",
    "plot_vmd_modes(t, signal, modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the time array\n",
    "fs = 1000  # Sampling frequency in Hz\n",
    "t = np.linspace(0, 1, fs, endpoint=False)  # Time vector from 0 to 1 second\n",
    "\n",
    "# Define the signal components\n",
    "signal1 = np.sin(2 * np.pi * 10 * t)  # 10 Hz sine wave\n",
    "signal2 = 0.5 * np.sin(2 * np.pi * 50 * t)  # 50 Hz sine wave with 0.5 amplitude\n",
    "\n",
    "# Combine the signals\n",
    "combined_signal = signal1 + signal2\n",
    "\n",
    "plt.figure(figsize=(25, 4))\n",
    "\n",
    "# Plot the 10 Hz component\n",
    "plt.plot(t, signal1, label=\"10 Hz Component\", color=\"blue\", alpha=0.7)\n",
    "\n",
    "# Plot the 50 Hz component\n",
    "plt.plot(t, signal2, label=\"50 Hz Component\", color=\"orange\", alpha=0.7)\n",
    "\n",
    "# Plot the combined signal\n",
    "plt.plot(t, combined_signal, label=\"Combined Signal\", color=\"green\", linewidth=1.5)\n",
    "\n",
    "plt.title(\"Signal Components and Combined Signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from main import GPU_VMD\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_vmd_modes_with_spectrum(t, signal, modes, sampling_rate):\n",
    "    \"\"\"\n",
    "    Plot the original signal, decomposed modes in time domain, and their frequency spectra.\n",
    "    \n",
    "    Parameters:\n",
    "    t (numpy array): Time values\n",
    "    signal (numpy array): Original signal\n",
    "    modes (list of numpy arrays): Decomposed modes\n",
    "    sampling_rate (float): Sampling rate of the signal (Hz)\n",
    "    \"\"\"\n",
    "    num_modes = len(modes)\n",
    "    fig, axes = plt.subplots(num_modes, 2, figsize=(12, 3 * num_modes))\n",
    "\n",
    "    # Iterate over each mode to plot time-domain and frequency-domain representations\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Plot time-domain waveform\n",
    "        axes[i, 0].plot(t, mode, label=f\"IMF{i+1}\", color='blue', linewidth=1)\n",
    "        axes[i, 0].set_title(f\"IMF{i+1} - Time Domain\")\n",
    "        axes[i, 0].set_xlabel(\"Time\")\n",
    "        axes[i, 0].set_ylabel(\"Amplitude\")\n",
    "        axes[i, 0].grid(True)\n",
    "        axes[i, 0].legend()\n",
    "\n",
    "        # Compute frequency spectrum\n",
    "        freq = np.fft.rfftfreq(len(mode), d=1/sampling_rate)\n",
    "        spectrum = np.abs(np.fft.rfft(mode))\n",
    "        \n",
    "        # Plot frequency spectrum\n",
    "        axes[i, 1].plot(freq, spectrum, label=f\"Frequency Spectrum of IMF{i+1}\", color='green', linewidth=1)\n",
    "        axes[i, 1].set_title(f\"IMF{i+1} - Frequency Domain\")\n",
    "        axes[i, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "        axes[i, 1].set_ylabel(\"Amplitude\")\n",
    "        axes[i, 1].grid(True)\n",
    "        axes[i, 1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Optional visualization function for spectrograms\n",
    "def plot_spectrogram(y, sr, title):\n",
    "    \"\"\"\n",
    "    Plot the spectrogram of a given signal using Librosa.\n",
    "    \n",
    "    Parameters:\n",
    "    y (numpy array): Audio signal\n",
    "    sr (int): Sampling rate\n",
    "    title (str): Title of the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    S = librosa.stft(y)  # Short-Time Fourier Transform\n",
    "    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)  # Convert amplitude to dB\n",
    "    librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log', cmap='magma')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Initialize the VMD\n",
    "vmd = GPU_VMD(\n",
    "    alpha=200000,  # Bandwidth constraint\n",
    "    tau=0,  # Noise-tolerance\n",
    "    n_modes=8,  # Number of modes to extract\n",
    "    dc_component=False,  # Whether to force first mode to be DC\n",
    "    init_method=1,  # Frequency initialization method\n",
    "    tolerance=1e-6,  # Convergence tolerance\n",
    "    device='cuda'  # Computing device\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the audio file\n",
    "sr, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "\n",
    "# Normalize the audio data to float32\n",
    "if data.dtype != np.float32:\n",
    "    data = data / np.max(np.abs(data), axis=0)  # Normalize to range [-1.0, 1.0]\n",
    "    data = data.astype(np.float32)\n",
    "\n",
    "# Decompose the signal using VMD\n",
    "result = vmd.decompose(data)\n",
    "modes = result.modes\n",
    "\n",
    "t = np.linspace(0, len(data) / sr, len(data))\n",
    "\n",
    "# Optional: Visualize the modes \n",
    "plot_vmd_modes_with_spectrum(t, data, modes, sr)\n",
    "\n",
    "# Plot spectrogram of the original signal\n",
    "plot_spectrogram(data, sr, \"Spectrogram of Original Signal\")\n",
    "\n",
    "# Plot spectrograms of each mode\n",
    "for i, mode in enumerate(modes):\n",
    "    plot_spectrogram(mode, sr, f\"Spectrogram of Mode {i + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from main import GPU_VMD\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_vmd_modes_with_spectrum(t, signal, modes, sampling_rate):\n",
    "    \"\"\" \n",
    "    Plot the original signal, decomposed modes in time domain, \n",
    "    their frequency spectra, and spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    t (numpy array): Time values\n",
    "    signal (numpy array): Original signal\n",
    "    modes (list of numpy arrays): Decomposed modes\n",
    "    sampling_rate (float): Sampling rate of the signal (Hz)\n",
    "    \"\"\"\n",
    "    num_modes = len(modes)\n",
    "    fig, axes = plt.subplots(num_modes + 1, 3, figsize=(36, 4 * (num_modes + 1)))\n",
    "    \n",
    "    # Plot original signal\n",
    "    axes[0, 0].plot(t[:2000], signal[:2000], label=\"Original Signal\", color='red', linewidth=1)\n",
    "    axes[0, 0].set_title(\"Original Signal - Time Domain\")\n",
    "    axes[0, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 0].grid(True)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Original signal frequency spectrum\n",
    "    freq = np.fft.rfftfreq(len(signal), d=1/sampling_rate)\n",
    "    spectrum = np.abs(np.fft.rfft(signal))\n",
    "    axes[0, 1].plot(freq, spectrum, label=\"Original Signal Frequency Spectrum\", color='red', linewidth=1)\n",
    "    axes[0, 1].set_title(\"Original Signal - Frequency Domain\")\n",
    "    axes[0, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "    axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 1].grid(True)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Original signal spectrogram\n",
    "    S = librosa.stft(signal)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "    librosa.display.specshow(S_db, sr=sampling_rate, x_axis='time', y_axis='log', \n",
    "                             cmap='magma', ax=axes[0, 2])\n",
    "    axes[0, 2].set_title(\"Original Signal Spectrogram\")\n",
    "    \n",
    "    # Iterate over each mode to plot time-domain, frequency-domain, and spectrogram\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Plot time-domain waveform\n",
    "        axes[i+1, 0].plot(t[:2000], mode[:2000], label=f\"IMF{i+1}\", color='blue', linewidth=1)\n",
    "        axes[i+1, 0].set_title(f\"IMF{i+1} - Time Domain\")\n",
    "        axes[i+1, 0].set_xlabel(\"Time (s)\")\n",
    "        axes[i+1, 0].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 0].grid(True)\n",
    "        axes[i+1, 0].legend()\n",
    "        \n",
    "        # Compute frequency spectrum\n",
    "        freq = np.fft.rfftfreq(len(mode), d=1/sampling_rate)\n",
    "        spectrum = np.abs(np.fft.rfft(mode))\n",
    "        axes[i+1, 1].plot(freq, spectrum, label=f\"Frequency Spectrum of IMF{i+1}\", color='green', linewidth=1)\n",
    "        axes[i+1, 1].set_title(f\"IMF{i+1} - Frequency Domain\")\n",
    "        axes[i+1, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "        axes[i+1, 1].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 1].grid(True)\n",
    "        axes[i+1, 1].legend()\n",
    "        \n",
    "        # Plot mode spectrogram\n",
    "        S_mode = librosa.stft(mode)\n",
    "        S_mode_db = librosa.amplitude_to_db(np.abs(S_mode), ref=np.max)\n",
    "        librosa.display.specshow(S_mode_db, sr=sampling_rate, x_axis='time', y_axis='log', \n",
    "                                 cmap='magma', ax=axes[i+1, 2])\n",
    "        axes[i+1, 2].set_title(f\"IMF{i+1} Spectrogram\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution script\n",
    "def main():\n",
    "    # Initialize the VMD\n",
    "    vmd = GPU_VMD(\n",
    "        alpha=200000,  # Bandwidth constraint\n",
    "        tau=0,  # Noise-tolerance\n",
    "        n_modes=20,  # Number of modes to extract\n",
    "        dc_component=False,  # Whether to force first mode to be DC\n",
    "        init_method=1,  # Frequency initialization method\n",
    "        tolerance=1e-6,  # Convergence tolerance\n",
    "        device='cuda'  # Computing device\n",
    "    )\n",
    "\n",
    "    # Read the audio file\n",
    "    sr, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "    \n",
    "    # Normalize the audio data to float32\n",
    "    if data.dtype != np.float32:\n",
    "        data = data / np.max(np.abs(data), axis=0)  # Normalize to range [-1.0, 1.0]\n",
    "        data = data.astype(np.float32)\n",
    "    \n",
    "    # Decompose the signal using VMD\n",
    "    result = vmd.decompose(data)\n",
    "    modes = result.modes\n",
    "    \n",
    "    # Create time array\n",
    "    t = np.linspace(0, len(data) / sr, len(data))\n",
    "    \n",
    "    # Visualize the modes with spectrograms\n",
    "    plot_vmd_modes_with_spectrum(t, data, modes, sr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fft\n",
    "import cupy as cp\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from main import GPU_VMD\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "def gpu_stft(signal, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Perform GPU-accelerated Short-Time Fourier Transform using PyTorch\n",
    "    \n",
    "    Parameters:\n",
    "    signal (numpy array): Input signal\n",
    "    n_fft (int): FFT window size\n",
    "    hop_length (int): Number of samples between successive frames\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: STFT result\n",
    "    \"\"\"\n",
    "    # Convert to torch tensor and move to GPU\n",
    "    signal_tensor = torch.from_numpy(signal).float().cuda()\n",
    "    \n",
    "    # Create window function on GPU\n",
    "    window = torch.hann_window(n_fft).cuda()\n",
    "    \n",
    "    # Perform STFT\n",
    "    stft_result = torch.stft(\n",
    "        signal_tensor, \n",
    "        n_fft=n_fft, \n",
    "        hop_length=hop_length, \n",
    "        window=window, \n",
    "        center=True, \n",
    "        return_complex=True\n",
    "    )\n",
    "    \n",
    "    return stft_result\n",
    "\n",
    "def plot_gpu_spectrogram(signal, sr, title, n_fft=2048, hop_length=512):\n",
    "    \"\"\"\n",
    "    Plot spectrogram using GPU-accelerated STFT\n",
    "    \n",
    "    Parameters:\n",
    "    signal (numpy array): Input signal\n",
    "    sr (int): Sampling rate\n",
    "    title (str): Plot title\n",
    "    n_fft (int): FFT window size\n",
    "    hop_length (int): Number of samples between successive frames\n",
    "    \"\"\"\n",
    "    # Compute GPU STFT\n",
    "    stft_result = gpu_stft(signal, n_fft, hop_length)\n",
    "    \n",
    "    # Convert to magnitude and move back to CPU for plotting\n",
    "    magnitude = torch.abs(stft_result).cpu().numpy()\n",
    "    \n",
    "    # Convert to dB scale\n",
    "    magnitude_db = librosa.amplitude_to_db(magnitude, ref=np.max)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(\n",
    "        magnitude_db, \n",
    "        sr=sr, \n",
    "        x_axis='time', \n",
    "        y_axis='log', \n",
    "        cmap='magma'\n",
    "    )\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_vmd_modes_with_gpu_spectrum(t, signal, modes, sampling_rate):\n",
    "    \"\"\" \n",
    "    Plot the original signal, decomposed modes in time domain, \n",
    "    their frequency spectra, and GPU-accelerated spectrograms.\n",
    "    \"\"\"\n",
    "    num_modes = len(modes)\n",
    "    fig, axes = plt.subplots(num_modes + 1, 3, figsize=(36, 4 * (num_modes + 1)))\n",
    "    \n",
    "    # Plot original signal\n",
    "    axes[0, 0].plot(t, signal, label=\"Original Signal\", color='red', linewidth=1)\n",
    "    axes[0, 0].set_title(\"Original Signal - Time Domain\")\n",
    "    axes[0, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 0].grid(True)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Original signal frequency spectrum\n",
    "    freq = np.fft.rfftfreq(len(signal), d=1/sampling_rate)\n",
    "    spectrum = np.abs(np.fft.rfft(signal))\n",
    "    axes[0, 1].plot(freq, spectrum, label=\"Original Signal Frequency Spectrum\", color='red', linewidth=1)\n",
    "    axes[0, 1].set_title(\"Original Signal - Frequency Domain\")\n",
    "    axes[0, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "    axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 1].grid(True)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Original signal spectrogram using GPU\n",
    "    stft_result = gpu_stft(signal)\n",
    "    magnitude = torch.abs(stft_result).cpu().numpy()\n",
    "    magnitude_db = librosa.amplitude_to_db(magnitude, ref=np.max)\n",
    "    librosa.display.specshow(\n",
    "        magnitude_db, \n",
    "        sr=sampling_rate, \n",
    "        x_axis='time', \n",
    "        y_axis='log', \n",
    "        cmap='magma', \n",
    "        ax=axes[0, 2]\n",
    "    )\n",
    "    axes[0, 2].set_title(\"Original Signal Spectrogram\")\n",
    "    \n",
    "    # Iterate over each mode to plot time-domain, frequency-domain, and spectrogram\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Plot time-domain waveform\n",
    "        axes[i+1, 0].plot(t, mode, label=f\"IMF{i+1}\", color='blue', linewidth=1)\n",
    "        axes[i+1, 0].set_title(f\"IMF{i+1} - Time Domain\")\n",
    "        axes[i+1, 0].set_xlabel(\"Time (s)\")\n",
    "        axes[i+1, 0].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 0].grid(True)\n",
    "        axes[i+1, 0].legend()\n",
    "        \n",
    "        # Compute frequency spectrum\n",
    "        freq = np.fft.rfftfreq(len(mode), d=1/sampling_rate)\n",
    "        spectrum = np.abs(np.fft.rfft(mode))\n",
    "        axes[i+1, 1].plot(freq, spectrum, label=f\"Frequency Spectrum of IMF{i+1}\", color='green', linewidth=1)\n",
    "        axes[i+1, 1].set_title(f\"IMF{i+1} - Frequency Domain\")\n",
    "        axes[i+1, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "        axes[i+1, 1].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 1].grid(True)\n",
    "        axes[i+1, 1].legend()\n",
    "        \n",
    "        # Plot mode spectrogram using GPU\n",
    "        mode_stft = gpu_stft(mode)\n",
    "        mode_magnitude = torch.abs(mode_stft).cpu().numpy()\n",
    "        mode_magnitude_db = librosa.amplitude_to_db(mode_magnitude, ref=np.max)\n",
    "        librosa.display.specshow(\n",
    "            mode_magnitude_db, \n",
    "            sr=sampling_rate, \n",
    "            x_axis='time', \n",
    "            y_axis='log', \n",
    "            cmap='magma', \n",
    "            ax=axes[i+1, 2]\n",
    "        )\n",
    "        axes[i+1, 2].set_title(f\"IMF{i+1} Spectrogram\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    # Initialize the VMD\n",
    "    vmd = GPU_VMD(\n",
    "        alpha=200000,  # Bandwidth constraint\n",
    "        tau=0,  # Noise-tolerance\n",
    "        n_modes=8,  # Number of modes to extract\n",
    "        dc_component=False,  # Whether to force first mode to be DC\n",
    "        init_method=1,  # Frequency initialization method\n",
    "        tolerance=1e-6,  # Convergence tolerance\n",
    "        device='cuda'  # Computing device\n",
    "    )\n",
    "\n",
    "    # Read the audio file\n",
    "    sr, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "    \n",
    "    # Normalize the audio data to float32\n",
    "    if data.dtype != np.float32:\n",
    "        data = data / np.max(np.abs(data), axis=0)  # Normalize to range [-1.0, 1.0]\n",
    "        data = data.astype(np.float32)\n",
    "    \n",
    "    # Decompose the signal using VMD\n",
    "    result = vmd.decompose(data)\n",
    "    modes = result.modes\n",
    "    \n",
    "    # Create time array\n",
    "    t = np.linspace(0, len(data) / sr, len(data))\n",
    "    \n",
    "    # Visualize the modes with GPU-accelerated spectrograms\n",
    "    plot_vmd_modes_with_gpu_spectrum(t, data, modes, sr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from main import GPU_VMD\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_vmd_modes_with_spectrum(t, signal, modes, sampling_rate, include_spectrogram=True, signal_plot_len=None):\n",
    "    \"\"\" \n",
    "    Plot the original signal, decomposed modes in time domain and their frequency spectra.\n",
    "    Optionally include spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    t (numpy array): Time values\n",
    "    signal (numpy array): Original signal\n",
    "    modes (list of numpy arrays): Decomposed modes\n",
    "    sampling_rate (float): Sampling rate of the signal (Hz)\n",
    "    include_spectrogram (bool): Whether to include spectrograms in the visualization\n",
    "    \"\"\"\n",
    "    num_modes = len(modes)\n",
    "    if signal_plot_len is None:\n",
    "        signal_plot_len=signal.shape[0]\n",
    "    \n",
    "    # Adjust subplot configuration based on spectrogram option\n",
    "    if include_spectrogram:\n",
    "        fig, axes = plt.subplots(num_modes + 1, 3, figsize=(36, 3 * (num_modes + 1)))\n",
    "        plot_columns = 3\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_modes + 1, 2, figsize=(24, 3 * (num_modes + 1)))\n",
    "        plot_columns = 2\n",
    "    \n",
    "    # Plot original signal - Time Domain\n",
    "    axes[0, 0].plot(t[:signal_plot_len], signal[:signal_plot_len], label=\"Original Signal\", color='red', linewidth=1)\n",
    "    axes[0, 0].set_title(\"Original Signal - Time Domain\")\n",
    "    axes[0, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 0].grid(True)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Original signal frequency spectrum\n",
    "    freq = np.fft.rfftfreq(len(signal), d=1/sampling_rate)\n",
    "    spectrum = np.abs(np.fft.rfft(signal))\n",
    "    axes[0, 1].plot(freq, spectrum, label=\"Original Signal Frequency Spectrum\", color='red', linewidth=1)\n",
    "    axes[0, 1].set_title(\"Original Signal - Frequency Domain\")\n",
    "    axes[0, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "    axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 1].grid(True)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Original signal spectrogram (if enabled)\n",
    "    if include_spectrogram:\n",
    "        S = librosa.stft(signal)\n",
    "        S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "        librosa.display.specshow(S_db, sr=sampling_rate, x_axis='time', y_axis='log', \n",
    "                                 cmap='magma', ax=axes[0, 2])\n",
    "        axes[0, 2].set_title(\"Original Signal Spectrogram\")\n",
    "    \n",
    "    # Iterate over each mode to plot time-domain and frequency-domain\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Plot time-domain waveform\n",
    "        axes[i+1, 0].plot(t[:signal_plot_len], mode[:signal_plot_len], label=f\"IMF{i+1}\", color='blue', linewidth=1)\n",
    "        axes[i+1, 0].set_title(f\"IMF{i+1} - Time Domain\")\n",
    "        axes[i+1, 0].set_xlabel(\"Time (s)\")\n",
    "        axes[i+1, 0].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 0].grid(True)\n",
    "        axes[i+1, 0].legend()\n",
    "        \n",
    "        # Compute frequency spectrum\n",
    "        freq = np.fft.rfftfreq(len(mode), d=1/sampling_rate)\n",
    "        spectrum = np.abs(np.fft.rfft(mode))\n",
    "        axes[i+1, 1].plot(freq, spectrum, label=f\"Frequency Spectrum of IMF{i+1}\", color='green', linewidth=1)\n",
    "        axes[i+1, 1].set_title(f\"IMF{i+1} - Frequency Domain\")\n",
    "        axes[i+1, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "        axes[i+1, 1].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 1].grid(True)\n",
    "        axes[i+1, 1].legend()\n",
    "        \n",
    "        # Plot mode spectrogram (if enabled)\n",
    "        if include_spectrogram:\n",
    "            S_mode = librosa.stft(mode)\n",
    "            S_mode_db = librosa.amplitude_to_db(np.abs(S_mode), ref=np.max)\n",
    "            librosa.display.specshow(S_mode_db, sr=sampling_rate, x_axis='time', y_axis='log', \n",
    "                                     cmap='magma', ax=axes[i+1, 2])\n",
    "            axes[i+1, 2].set_title(f\"IMF{i+1} Spectrogram\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution script\n",
    "def main(include_spectrogram=True):\n",
    "    # Initialize the VMD\n",
    "    vmd = GPU_VMD(\n",
    "        alpha=200000,  # Bandwidth constraint\n",
    "        tau=0,  # Noise-tolerance\n",
    "        n_modes=8,  # Number of modes to extract\n",
    "        dc_component=False,  # Whether to force first mode to be DC\n",
    "        init_method=1,  # Frequency initialization method\n",
    "        tolerance=1e-6,  # Convergence tolerance\n",
    "        device='cuda'  # Computing device\n",
    "    )\n",
    "\n",
    "    # Read the audio file\n",
    "    sr, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "    \n",
    "    # Normalize the audio data to float32\n",
    "    if data.dtype != np.float32:\n",
    "        data = data / np.max(np.abs(data), axis=0)  # Normalize to range [-1.0, 1.0]\n",
    "        data = data.astype(np.float32)\n",
    "    \n",
    "    # Decompose the signal using VMD\n",
    "    result = vmd.decompose(data, data.shape[0])\n",
    "    modes = result.modes\n",
    "    \n",
    "    # Create time array\n",
    "    t = np.linspace(0, len(data) / sr, len(data))\n",
    "    \n",
    "    # Visualize the modes with optional spectrograms\n",
    "    plot_vmd_modes_with_spectrum(t, data, modes, sr, include_spectrogram, signal_plot_len=2000)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can now choose whether to include spectrograms\n",
    "    main(include_spectrogram=True)   # For full visualization\n",
    "    # main(include_spectrogram=False)  # For a more compact view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "from main import GPU_VMD\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_vmd_modes_with_spectrum(t, signal, modes, sampling_rate, include_spectrogram=True, signal_plot_len=None):\n",
    "    \"\"\" \n",
    "    Plot the original signal, decomposed modes in time domain and their frequency spectra.\n",
    "    Optionally include spectrograms.\n",
    "    \n",
    "    Parameters:\n",
    "    t (numpy array): Time values\n",
    "    signal (numpy array): Original signal\n",
    "    modes (list of numpy arrays): Decomposed modes\n",
    "    sampling_rate (float): Sampling rate of the signal (Hz)\n",
    "    include_spectrogram (bool): Whether to include spectrograms in the visualization\n",
    "    \"\"\"\n",
    "    num_modes = len(modes)\n",
    "    if signal_plot_len is None:\n",
    "        signal_plot_len=signal.shape[0]\n",
    "    \n",
    "    # Adjust subplot configuration based on spectrogram option\n",
    "    if include_spectrogram:\n",
    "        fig, axes = plt.subplots(num_modes + 1, 3, figsize=(36, 3 * (num_modes + 1)))\n",
    "        plot_columns = 3\n",
    "    else:\n",
    "        fig, axes = plt.subplots(num_modes + 1, 2, figsize=(24, 3 * (num_modes + 1)))\n",
    "        plot_columns = 2\n",
    "    \n",
    "    # Plot original signal - Time Domain\n",
    "    axes[0, 0].plot(t[:signal_plot_len], signal[:signal_plot_len], label=\"Original Signal\", color='red', linewidth=1)\n",
    "    axes[0, 0].set_title(\"Original Signal - Time Domain\")\n",
    "    axes[0, 0].set_xlabel(\"Time (s)\")\n",
    "    axes[0, 0].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 0].grid(True)\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Original signal frequency spectrum\n",
    "    freq = np.fft.rfftfreq(len(signal), d=1/sampling_rate)\n",
    "    spectrum = np.abs(np.fft.rfft(signal))\n",
    "    axes[0, 1].plot(freq, spectrum, label=\"Original Signal Frequency Spectrum\", color='red', linewidth=1)\n",
    "    axes[0, 1].set_title(\"Original Signal - Frequency Domain\")\n",
    "    axes[0, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "    axes[0, 1].set_ylabel(\"Amplitude\")\n",
    "    axes[0, 1].grid(True)\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Original signal spectrogram (if enabled)\n",
    "    if include_spectrogram:\n",
    "        S = librosa.stft(signal)\n",
    "        S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
    "        librosa.display.specshow(S_db, sr=sampling_rate, x_axis='time', y_axis='log', \n",
    "                                 cmap='magma', ax=axes[0, 2])\n",
    "        axes[0, 2].set_title(\"Original Signal Spectrogram\")\n",
    "    \n",
    "    # Iterate over each mode to plot time-domain and frequency-domain\n",
    "    for i, mode in enumerate(modes):\n",
    "        # Plot time-domain waveform\n",
    "        axes[i+1, 0].plot(t[:signal_plot_len], mode[:signal_plot_len], label=f\"IMF{i+1}\", color='blue', linewidth=1)\n",
    "        axes[i+1, 0].set_title(f\"IMF{i+1} - Time Domain\")\n",
    "        axes[i+1, 0].set_xlabel(\"Time (s)\")\n",
    "        axes[i+1, 0].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 0].grid(True)\n",
    "        axes[i+1, 0].legend()\n",
    "        \n",
    "        # Compute frequency spectrum\n",
    "        freq = np.fft.rfftfreq(len(mode), d=1/sampling_rate)\n",
    "        spectrum = np.abs(np.fft.rfft(mode))\n",
    "        axes[i+1, 1].plot(freq, spectrum, label=f\"Frequency Spectrum of IMF{i+1}\", color='green', linewidth=1)\n",
    "        axes[i+1, 1].set_title(f\"IMF{i+1} - Frequency Domain\")\n",
    "        axes[i+1, 1].set_xlabel(\"Frequency (Hz)\")\n",
    "        axes[i+1, 1].set_ylabel(\"Amplitude\")\n",
    "        axes[i+1, 1].grid(True)\n",
    "        axes[i+1, 1].legend()\n",
    "        \n",
    "        # Plot mode spectrogram (if enabled)\n",
    "        if include_spectrogram:\n",
    "            S_mode = librosa.stft(mode)\n",
    "            S_mode_db = librosa.amplitude_to_db(np.abs(S_mode), ref=np.max)\n",
    "            librosa.display.specshow(S_mode_db, sr=sampling_rate, x_axis='time', y_axis='log', \n",
    "                                     cmap='magma', ax=axes[i+1, 2])\n",
    "            axes[i+1, 2].set_title(f\"IMF{i+1} Spectrogram\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main execution script\n",
    "def main(include_spectrogram=True):\n",
    "    # Initialize the VMD\n",
    "    vmd = GPU_VMD(\n",
    "        alpha=200000,  # Bandwidth constraint\n",
    "        tau=0,  # Noise-tolerance\n",
    "        n_modes=5,  # Number of modes to extract\n",
    "        dc_component=False,  # Whether to force first mode to be DC\n",
    "        init_method=1,  # Frequency initialization method\n",
    "        tolerance=1e-6,  # Convergence tolerance\n",
    "        device='cuda'  # Computing device\n",
    "    )\n",
    "\n",
    "    # Read the audio file\n",
    "    sr, data = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\VMD\\filtered_speech.wav')\n",
    "    \n",
    "    # Normalize the audio data to float32\n",
    "    if data.dtype != np.float32:\n",
    "        data = data / np.max(np.abs(data), axis=0)  # Normalize to range [-1.0, 1.0]\n",
    "        data = data.astype(np.float32)\n",
    "    \n",
    "    # Decompose the signal using VMD\n",
    "    result = vmd.decompose(data, data.shape[0])\n",
    "    modes = result.modes\n",
    "    \n",
    "    # Create time array\n",
    "    t = np.linspace(0, len(data) / sr, len(data))\n",
    "    \n",
    "    # Visualize the modes with optional spectrograms\n",
    "    plot_vmd_modes_with_spectrum(t, data, modes, sr, include_spectrogram, signal_plot_len=None)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can now choose whether to include spectrograms\n",
    "    main(include_spectrogram=True)   # For full visualization\n",
    "    # main(include_spectrogram=False)  # For a more compact view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def compute_and_plot_spectrograms(file1_path, file2_path):\n",
    "    \"\"\"\n",
    "    Read two WAV files, compute their spectrograms, and plot them side by side.\n",
    "    \n",
    "    Parameters:\n",
    "    file1_path (str): Path to the first WAV file\n",
    "    file2_path (str): Path to the second WAV file\n",
    "    \"\"\"\n",
    "    # Load the audio files\n",
    "    y1, sr1 = librosa.load(file1_path)\n",
    "    y2, sr2 = librosa.load(file2_path)\n",
    "    \n",
    "    # Compute spectrograms\n",
    "    # Using librosa's stft (Short-time Fourier Transform)\n",
    "    D1 = librosa.stft(y1)\n",
    "    D2 = librosa.stft(y2)\n",
    "    \n",
    "    # Convert to decibel scale\n",
    "    DB1 = librosa.amplitude_to_db(np.abs(D1), ref=np.max)\n",
    "    DB2 = librosa.amplitude_to_db(np.abs(D2), ref=np.max)\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot first spectrogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    librosa.display.specshow(DB1, sr=sr1, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Spectrogram of {file1_path.split(\"/\")[-1]}')\n",
    "    \n",
    "    # Plot second spectrogram\n",
    "    plt.subplot(1, 2, 2)\n",
    "    librosa.display.specshow(DB2, sr=sr2, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Spectrogram of {file2_path.split(\"/\")[-1]}')\n",
    "    \n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these paths with the actual paths to your WAV files\n",
    "    file1 = r\"C:\\Users\\Arun\\parkinson-s-classify\\VMD\\filtered_speech.wav\"\n",
    "    file2 = r\"C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav\"\n",
    "    \n",
    "    compute_and_plot_spectrograms(file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import wiener\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Read the noisy speech signal\n",
    "sample_rate, noisy_signal = wavfile.read(r'C:\\Users\\Arun\\parkinson-s-classify\\neurovoz_v3\\data\\audios\\HC_A1_0034.wav')\n",
    "\n",
    "# Check the signal properties\n",
    "print(f\"Sample Rate: {sample_rate} Hz\")\n",
    "print(f\"Signal Length: {len(noisy_signal)} samples\")\n",
    "\n",
    "# Normalize the signal if it's in int16 format\n",
    "if noisy_signal.dtype == np.int16:\n",
    "    noisy_signal = noisy_signal / np.max(np.abs(noisy_signal))\n",
    "\n",
    "# Step 2: Apply Wiener filtering\n",
    "filtered_signal = wiener(noisy_signal)\n",
    "\n",
    "# Step 3: Save the filtered output\n",
    "wavfile.write('filtered_speech.wav', sample_rate, np.int16(filtered_signal * 32767))\n",
    "\n",
    "# Plot the original and filtered signals for comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Noisy Speech Signal')\n",
    "plt.plot(noisy_signal, color='red')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Filtered Speech Signal (Wiener)')\n",
    "plt.plot(filtered_signal, color='green')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12819673374699317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import GPU_VMD, save_modes_and_reconstruct\n",
    "from scipy.signal import wiener\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "vmd = GPU_VMD(\n",
    "        alpha=200000,\n",
    "        tau=0,\n",
    "        n_modes=20,\n",
    "        dc_component=False,\n",
    "        init_method=1,\n",
    "        tolerance=1e-10,\n",
    "        device='cuda'\n",
    "    )\n",
    "# # Load the audio file\n",
    "audio_path = r'E:\\Amrita\\Subjects\\Sem 5\\BMSP paper work\\Dataset\\neurovoz_v3\\data\\audios\\HC_A1_0049.wav'\n",
    "data, sr = librosa.load(audio_path)\n",
    "data = wiener(data)\n",
    "\n",
    "# file_path = r'C:\\Users\\Arun\\Downloads\\OneDrive_1_12-13-2024\\Folder 1\\arctic_a0004.wav'\n",
    "# data, sr = librosa.load(file_path, mono=False)\n",
    "\n",
    "# data = data[0]\n",
    "result = vmd.decompose(data, data.shape[0])\n",
    "modes = result.modes\n",
    "\n",
    "# Pad each mode to the same length of the original signal\n",
    "modes_padded = []\n",
    "for mode in modes:\n",
    "    mode_padded = np.pad(mode, (0, len(data) - len(mode)), 'constant')\n",
    "    modes_padded.append(mode_padded)\n",
    "\n",
    "# Save the decomposed modes and reconstructed signal\n",
    "save_modes_and_reconstruct(modes_padded, sr, data, 'summa1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
